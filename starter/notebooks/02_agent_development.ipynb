{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c05535",
   "metadata": {},
   "source": [
    "# ü§ñ Agent Development - Risk Analyst & Compliance Officer\n",
    "\n",
    "Welcome to Phase 2 & 3 of the project! In this notebook, you'll develop and test both AI agents:\n",
    "\n",
    "1. **Risk Analyst Agent** (Chain-of-Thought prompting)\n",
    "2. **Compliance Officer Agent** (ReACT prompting)\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Implement Chain-of-Thought prompting for systematic reasoning\n",
    "- Build ReACT prompting for structured action-taking\n",
    "- Handle structured JSON outputs from LLMs\n",
    "- Create robust error handling and validation\n",
    "- Test agents with real financial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e589df2",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7340da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Libraries loaded!\n",
      "üîê Environment variables loaded\n",
      "üìÇ Source directory added to Python path: c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\\src\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src directory to Python path for module imports\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "print(\"üìö Libraries loaded!\")\n",
    "print(\"üîê Environment variables loaded\")\n",
    "print(\"üìÇ Source directory added to Python path:\", os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aec4374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized with Vocareum routing\n",
      "üîë API key: voc-1769...4816\n",
      "üìç Base URL: https://openai.vocareum.com/v1\n",
      "\n",
      "üí° Tip: After implementing foundation_sar.py, you can use:\n",
      "   from src import create_vocareum_openai_client\n",
      "   client = create_vocareum_openai_client()\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Option 2: Manual setup (for early development)\n",
    "openai_api_key = os.getenv('OPENAI_VOCAREUM_API_KEY')\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"‚ö†Ô∏è WARNING: No OpenAI API key found!\")\n",
    "    print(\"Please set OPENAI_VOCAREUM_API_KEY in your .env file\")\n",
    "    print(\"Get your Vocareum OpenAI API key from 'Cloud Resources' in your workspace\")\n",
    "else:\n",
    "    # Vocareum requires routing through their servers\n",
    "    client = openai.OpenAI(\n",
    "        base_url=\"https://openai.vocareum.com/v1\",\n",
    "        api_key=openai_api_key\n",
    "    )\n",
    "    print(\"‚úÖ OpenAI client initialized with Vocareum routing\")\n",
    "    print(f\"üîë API key: {openai_api_key[:8]}...{openai_api_key[-4:]}\")\n",
    "    print(\"üìç Base URL: https://openai.vocareum.com/v1\")\n",
    "    print(\"\\nüí° Tip: After implementing foundation_sar.py, you can use:\")\n",
    "    print(\"   from src import create_vocareum_openai_client\")\n",
    "    print(\"   client = create_vocareum_openai_client()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0aa27",
   "metadata": {},
   "source": [
    "## üìä Phase 1 Review: Load Foundation Components\n",
    "\n",
    "Before building agents, let's ensure your foundation components are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a253106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã TODO: Import foundation components after implementing foundation_sar.py\n",
      "‚úÖ Once imported, you can create sample cases for agent testing\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import your implemented foundation components\n",
    "# Uncomment and modify these imports once you've implemented foundation_sar.py\n",
    "\n",
    "from foundation_sar import (\n",
    "     CustomerData,\n",
    "     AccountData,\n",
    "     TransactionData,\n",
    "     CaseData,\n",
    "     RiskAnalystOutput,\n",
    "     ComplianceOfficerOutput,\n",
    "     ExplainabilityLogger,\n",
    "     DataLoader,\n",
    "     load_csv_data,\n",
    "     normalize_transaction_dict\n",
    ")\n",
    "from risk_analyst_agent import RiskAnalystAgent\n",
    "\n",
    "print(\"üìã TODO: Import foundation components after implementing foundation_sar.py\")\n",
    "print(\"‚úÖ Once imported, you can create sample cases for agent testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69f2af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Testing foundation components\n",
      "1. Load CSV data from ../data/\n",
      "2. Create ExplainabilityLogger instance\n",
      "3. Create DataLoader instance\n",
      "4. Generate sample case for agent testing\n",
      "\n",
      "‚úÖ CSVs loaded\n",
      "   customers:     (150, 10)\n",
      "   accounts:      (178, 7)\n",
      "   transactions:  (4268, 9)\n",
      "\n",
      "‚úÖ Sample case created\n",
      "   case_id: bd1c6a45-3ba2-4001-9312-49b89261281b\n",
      "   customer_id: CUST_0002\n",
      "   accounts: 1\n",
      "   transactions: 11\n",
      "\n",
      "üßæ Audit log status\n",
      "   entries_in_memory: 1\n",
      "   last_entry_agent_type: DataLoader\n",
      "   log_file_written: True\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test foundation components\n",
    "# Once you've implemented foundation_sar.py, use this cell to:\n",
    "# 1. Load CSV data\n",
    "# 2. Create a DataLoader instance\n",
    "# 3. Generate a sample case for testing agents\n",
    "\n",
    "print(\"üìã Testing foundation components\")\n",
    "print(\"1. Load CSV data from ../data/\")\n",
    "print(\"2. Create ExplainabilityLogger instance\")\n",
    "print(\"3. Create DataLoader instance\")\n",
    "print(\"4. Generate sample case for agent testing\\n\")\n",
    "\n",
    "# --- 1) Ensure output folder exists ---\n",
    "audit_log_path = \"../outputs/audit_logs/agent_development.jsonl\"\n",
    "os.makedirs(os.path.dirname(audit_log_path), exist_ok=True)\n",
    "\n",
    "# --- 2) Create logger and loader ---\n",
    "logger = ExplainabilityLogger(audit_log_path)\n",
    "loader = DataLoader(logger)\n",
    "\n",
    "# --- 3) Load CSVs ---\n",
    "customers_df, accounts_df, transactions_df = load_csv_data(\"../data/\")\n",
    "\n",
    "print(\"‚úÖ CSVs loaded\")\n",
    "print(f\"   customers:     {customers_df.shape}\")\n",
    "print(f\"   accounts:      {accounts_df.shape}\")\n",
    "print(f\"   transactions:  {transactions_df.shape}\\n\")\n",
    "\n",
    "# --- 4) Generate a sample case (pick first customer with at least 1 account + 1 txn) ---\n",
    "sample_case = None\n",
    "\n",
    "# Index for faster filtering\n",
    "accounts_by_customer = accounts_df.groupby(\"customer_id\")\n",
    "txns_by_account = transactions_df.groupby(\"account_id\")\n",
    "\n",
    "for _, cust_row in customers_df.iterrows():\n",
    "    cust_id = cust_row[\"customer_id\"]\n",
    "\n",
    "    if cust_id not in accounts_by_customer.groups:\n",
    "        continue\n",
    "\n",
    "    cust_accounts_df = accounts_by_customer.get_group(cust_id)\n",
    "    account_ids = set(cust_accounts_df[\"account_id\"].tolist())\n",
    "\n",
    "    # Gather txns for those accounts\n",
    "    cust_txns_list = []\n",
    "    for acc_id in account_ids:\n",
    "        if acc_id in txns_by_account.groups:\n",
    "            cust_txns_list.extend(txns_by_account.get_group(acc_id).to_dict(orient=\"records\"))\n",
    "\n",
    "    # CaseData validator requires non-empty transactions\n",
    "    if not cust_txns_list:\n",
    "        continue\n",
    "\n",
    "    # Build dict payloads for DataLoader\n",
    "    customer_data = cust_row.to_dict()\n",
    "    if \"ssn_last_4\" in customer_data:\n",
    "        customer_data[\"ssn_last_4\"] = str(customer_data[\"ssn_last_4\"]).zfill(4)\n",
    "\n",
    "    account_data = cust_accounts_df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Normalize transaction dicts to satisfy TransactionData Optional[str] fields\n",
    "    cust_txns_list = [normalize_transaction_dict(t) for t in cust_txns_list]\n",
    "\n",
    "    # Create the case via DataLoader (logs an audit entry)\n",
    "    sample_case = loader.create_case_from_data(\n",
    "        customer_data=customer_data,\n",
    "        account_data=account_data,\n",
    "        transaction_data=cust_txns_list,\n",
    "    )\n",
    "    break\n",
    "\n",
    "if sample_case is None:\n",
    "    raise RuntimeError(\n",
    "        \"No valid sample case found. Ensure your CSVs contain at least one customer with \"\n",
    "        \"an account and at least one transaction linked to that account.\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Sample case created\")\n",
    "print(f\"   case_id: {sample_case.case_id}\")\n",
    "print(f\"   customer_id: {sample_case.customer.customer_id}\")\n",
    "print(f\"   accounts: {len(sample_case.accounts)}\")\n",
    "print(f\"   transactions: {len(sample_case.transactions)}\")\n",
    "\n",
    "# --- 5) Quick audit log validation ---\n",
    "print(\"\\nüßæ Audit log status\")\n",
    "print(f\"   entries_in_memory: {len(logger.entries)}\")\n",
    "print(f\"   last_entry_agent_type: {logger.entries[-1].get('agent_type') if logger.entries else None}\")\n",
    "print(f\"   log_file_written: {os.path.exists(audit_log_path)}\")\n",
    "\n",
    "# sample_case is now ready to be used by agents in later cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86feae7",
   "metadata": {},
   "source": [
    "## üîç Phase 2: Risk Analyst Agent Development\n",
    "\n",
    "The Risk Analyst Agent uses **Chain-of-Thought prompting** to systematically analyze suspicious activity patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106f6ad",
   "metadata": {},
   "source": [
    "### üìö Understanding Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting guides AI models through step-by-step reasoning:\n",
    "\n",
    "1. **Explicit Steps**: Break complex reasoning into clear phases\n",
    "2. **Sequential Logic**: Each step builds on previous ones\n",
    "3. **Domain Expertise**: Frame AI as subject matter expert\n",
    "4. **Structured Output**: Guide toward specific response format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae133c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Chain-of-Thought Prompt Design:\n",
      "\n",
      "    You are a Senior Financial Crime Risk Analyst specializing in Suspicious Activity Report (SAR) triage.\n",
      "\n",
      "    Use Chain-of-Thought (step-by-step reasoning) internally to analyze the case in five ph...\n",
      "\n",
      "üìã Next step: Ensure the same prompt (or equivalent) is set in risk_analyst_agent.py as agent.system_prompt\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test Chain-of-Thought prompt design\n",
    "# This cell helps you design and test your CoT prompt structure\n",
    "\n",
    "def design_cot_prompt():\n",
    "    \"\"\"Design and test Chain-of-Thought prompt for risk analysis\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are a Senior Financial Crime Risk Analyst specializing in Suspicious Activity Report (SAR) triage.\n",
    "\n",
    "    Use Chain-of-Thought (step-by-step reasoning) internally to analyze the case in five phases:\n",
    "    1) Data Review: Summarize customer profile, accounts, and transactions.\n",
    "    2) Pattern Recognition: Identify unusual behavior and suspicious patterns (amounts, frequency, channels, counterparties, geographies).\n",
    "    3) Regulatory Mapping: Map observed indicators to common AML typologies and red flags.\n",
    "    4) Risk Quantification: Assign a risk_level (Low|Medium|High|Critical) and a confidence_score (0.0‚Äì1.0) based on evidence strength.\n",
    "    5) Classification Decision: Choose one primary classification and justify it concisely.\n",
    "\n",
    "    Classification categories (choose exactly ONE):\n",
    "    - Structuring\n",
    "    - Sanctions\n",
    "    - Fraud\n",
    "    - Money_Laundering\n",
    "    - Other\n",
    "\n",
    "    Output requirements:\n",
    "    - Return ONLY valid JSON (no markdown, no extra text).\n",
    "    - Use exactly the following schema:\n",
    "\n",
    "    {\n",
    "    \"classification\": \"Structuring|Sanctions|Fraud|Money_Laundering|Other\",\n",
    "    \"confidence_score\": 0.0-1.0,\n",
    "    \"reasoning\": \"Concise rationale referencing the key facts and indicators\",\n",
    "    \"key_indicators\": [\"indicator1\", \"indicator2\", \"indicator3\"],\n",
    "    \"risk_level\": \"Low|Medium|High|Critical\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    return system_prompt\n",
    "\n",
    "# Test your prompt design\n",
    "cot_prompt = design_cot_prompt()\n",
    "print(\"üß† Chain-of-Thought Prompt Design:\")\n",
    "print(cot_prompt[:200] + \"...\")\n",
    "print(\"\\nüìã Next step: Ensure the same prompt (or equivalent) is set in risk_analyst_agent.py as agent.system_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86040698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SUCCESS: classification='Structuring', confidence=0.82\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement and test Risk Analyst Agent - SIMPLE SMOKE TEST\n",
    "# Students: Write a basic smoke test to verify your agent works\n",
    "\n",
    "def simple_risk_analyst_smoke_test():\n",
    "    # ---- Fake OpenAI client (prevents external calls) ----\n",
    "    class _FakeChoiceMsg:\n",
    "        def __init__(self, content: str):\n",
    "            self.content = content\n",
    "\n",
    "    class _FakeChoice:\n",
    "        def __init__(self, content: str):\n",
    "            self.message = _FakeChoiceMsg(content)\n",
    "\n",
    "    class _FakeResponse:\n",
    "        def __init__(self, content: str):\n",
    "            self.choices = [_FakeChoice(content)]\n",
    "\n",
    "    class _FakeChatCompletions:\n",
    "        def create(self, model, temperature, max_tokens, messages):\n",
    "            output = RiskAnalystOutput(\n",
    "                classification=\"Structuring\",\n",
    "                confidence_score=0.82,\n",
    "                reasoning=\"Repeated cash deposits close to reporting thresholds indicate possible structuring.\",\n",
    "                key_indicators=[\n",
    "                    \"near-threshold cash deposits\",\n",
    "                    \"repeated deposits\"\n",
    "                ],\n",
    "                risk_level=\"High\",\n",
    "            )\n",
    "\n",
    "            return _FakeResponse(\n",
    "                json.dumps(output.model_dump())\n",
    "            )\n",
    "\n",
    "    class _FakeChat:\n",
    "        def __init__(self):\n",
    "            self.completions = _FakeChatCompletions()\n",
    "\n",
    "    class FakeOpenAIClient:\n",
    "        def __init__(self):\n",
    "            self.chat = _FakeChat()\n",
    "\n",
    "    # ---- Create VALID test data (must satisfy foundation_sar validators) ----\n",
    "    customer = CustomerData(\n",
    "        customer_id=\"CUST_0001\",\n",
    "        name=\"John Doe\",\n",
    "        date_of_birth=\"1985-04-12\",\n",
    "        ssn_last_4=\"1234\",\n",
    "        address=\"123 Main St, Miami, FL\",\n",
    "        customer_since=\"2018-06-01\",\n",
    "        risk_rating=\"Medium\",\n",
    "    )\n",
    "\n",
    "    account = AccountData(\n",
    "        account_id=\"CUST_0001_ACC_1\",\n",
    "        customer_id=\"CUST_0001\",\n",
    "        account_type=\"Checking\",\n",
    "        opening_date=\"2018-06-01\",\n",
    "        current_balance=15250.75,\n",
    "        average_monthly_balance=12000.50,\n",
    "        status=\"Active\",\n",
    "    )\n",
    "\n",
    "    txn = TransactionData(\n",
    "        transaction_id=\"TXN_0001\",\n",
    "        account_id=\"CUST_0001_ACC_1\",  # must match account_id above\n",
    "        transaction_date=\"2025-01-01\",\n",
    "        transaction_type=\"Cash_Deposit\",\n",
    "        amount=9900.00,\n",
    "        description=\"Cash deposit at branch\",\n",
    "        method=\"Branch\",\n",
    "        location=\"Miami, FL\",\n",
    "        counterparty=None,\n",
    "    )\n",
    "\n",
    "    case = CaseData(\n",
    "        case_id=\"CASE_SMOKE_0001\",\n",
    "        customer=customer,\n",
    "        accounts=[account],\n",
    "        transactions=[txn],  # cannot be empty\n",
    "        case_created_at=datetime.now().isoformat(),\n",
    "        data_sources={\"test\": \"smoke\"},\n",
    "    )\n",
    "\n",
    "    # ---- Initialize agent + logger ----\n",
    "    audit_path = \"outputs_smoke_test.jsonl\"\n",
    "    logger = ExplainabilityLogger(audit_path)\n",
    "    client = FakeOpenAIClient()\n",
    "    agent = RiskAnalystAgent(client, logger, model=\"gpt-4\")\n",
    "\n",
    "    # ---- Run + validate ----\n",
    "    try:\n",
    "        result = agent.analyze_case(case)\n",
    "\n",
    "        # Basic structure checks\n",
    "        assert result is not None\n",
    "        assert hasattr(result, \"classification\")\n",
    "        assert hasattr(result, \"confidence_score\")\n",
    "        assert hasattr(result, \"reasoning\")\n",
    "        assert hasattr(result, \"key_indicators\")\n",
    "        assert hasattr(result, \"risk_level\")\n",
    "\n",
    "        assert result.classification in [\"Structuring\", \"Sanctions\", \"Fraud\", \"Money_Laundering\", \"Other\"]\n",
    "        assert 0.0 <= float(result.confidence_score) <= 1.0\n",
    "        assert isinstance(result.reasoning, str) and len(result.reasoning) > 0\n",
    "        assert isinstance(result.key_indicators, list)\n",
    "        assert result.risk_level in [\"Low\", \"Medium\", \"High\", \"Critical\"]\n",
    "\n",
    "        # Logging checks\n",
    "        assert len(logger.entries) >= 1\n",
    "        assert logger.entries[-1][\"agent_type\"] == \"RiskAnalyst\"\n",
    "        assert logger.entries[-1][\"success\"] is True\n",
    "\n",
    "        print(f\"‚úÖ SUCCESS: classification='{result.classification}', confidence={result.confidence_score}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå FAILED: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Optional cleanup (keep file if you want evidence)\n",
    "        if os.path.exists(audit_path):\n",
    "            os.remove(audit_path)\n",
    "\n",
    "# Run the smoke test\n",
    "simple_risk_analyst_smoke_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b21e2fa",
   "metadata": {},
   "source": [
    "### üß™ Risk Analyst Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02640ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Added tests directory to Python path: c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\\tests\n",
      "\n",
      "üìä Preview of Comprehensive Risk Analyst Tests:\n",
      "   ‚Ä¢ Test RiskAnalystAgent initializes properly\n",
      "   ‚Ä¢ Test handling of invalid JSON response\n",
      "   ‚Ä¢ Test successful case analysis with valid response\n",
      "   ‚Ä¢ Test OpenAI API call uses correct parameters\n",
      "   ‚Ä¢ Test handling of empty LLM response\n",
      "   ... and 5 more tests\n",
      "\n",
      "üí° These tests validate edge cases you might not think of!\n",
      "üí° Much more thorough than manual testing!\n",
      "üß™ Comprehensive Risk Analyst Testing (TIER 2)\n",
      "üîç Running test suite: c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\\tests\\test_risk_analyst.py\n",
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.10.11, pytest-9.0.2, pluggy-1.6.0 -- c:\\Program Files\\Python310\\python.exe\n",
      "rootdir: c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\n",
      "plugins: anyio-4.11.0, langsmith-0.4.42\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 10 items\n",
      "\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_agent_initialization \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_analyze_case_success \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_analyze_case_json_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_extract_json_from_code_block \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_extract_json_from_plain_text \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_extract_json_empty_response \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_format_accounts \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_format_transactions \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_system_prompt_structure \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_api_call_parameters \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m10 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "‚úÖ All Risk Analyst tests passed!\n"
     ]
    }
   ],
   "source": [
    "# COMPREHENSIVE Risk Analyst Testing - Import Pre-Built Test Suite\n",
    "# Students: Use our comprehensive test suite instead of writing your own\n",
    "\n",
    "import pytest\n",
    "\n",
    "# Notebook normalmente em: starter/notebooks\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "\n",
    "# Caminho para: starter (raiz do projeto dentro de starter/)\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "# Caminho para: starter/tests\n",
    "tests_path = os.path.join(PROJECT_ROOT, \"tests\")\n",
    "\n",
    "if tests_path not in sys.path:\n",
    "    sys.path.insert(0, tests_path)\n",
    "\n",
    "print(f\"üìÅ Added tests directory to Python path: {tests_path}\")\n",
    "\n",
    "def run_comprehensive_risk_analyst_tests():\n",
    "    \"\"\"\n",
    "    Use pre-built comprehensive test suite to validate your Risk Analyst Agent\n",
    "\n",
    "    These tests validate:\n",
    "    - Agent initialization and configuration\n",
    "    - Case analysis with valid inputs\n",
    "    - JSON parsing and error handling\n",
    "    - System prompt structure and content\n",
    "    - API call parameters and responses\n",
    "    - Helper method functionality\n",
    "    \"\"\"\n",
    "    print(\"üß™ Comprehensive Risk Analyst Testing (TIER 2)\")\n",
    "\n",
    "    test_file = os.path.join(tests_path, \"test_risk_analyst.py\")\n",
    "    if not os.path.exists(test_file):\n",
    "        raise FileNotFoundError(f\"Test file not found: {test_file}\")\n",
    "\n",
    "    print(f\"üîç Running test suite: {test_file}\")\n",
    "\n",
    "    result = pytest.main([\n",
    "        test_file,\n",
    "        \"-v\",\n",
    "        \"--tb=short\",\n",
    "        \"-p\", \"no:cacheprovider\",\n",
    "        \"-W\", \"ignore::pytest.PytestAssertRewriteWarning\",\n",
    "    ])\n",
    "\n",
    "    if result == 0:\n",
    "        print(\"‚úÖ All Risk Analyst tests passed!\")\n",
    "    else:\n",
    "        raise RuntimeError(\"‚ùå Some tests failed. Check pytest output above.\")\n",
    "\n",
    "# Quick preview of available tests\n",
    "try:\n",
    "    from test_risk_analyst import TestRiskAnalystAgent\n",
    "\n",
    "    test_methods = [m for m in dir(TestRiskAnalystAgent) if m.startswith(\"test_\")]\n",
    "\n",
    "    print(\"\\nüìä Preview of Comprehensive Risk Analyst Tests:\")\n",
    "    for method_name in test_methods[:5]:\n",
    "        method = getattr(TestRiskAnalystAgent, method_name)\n",
    "        doc = method.__doc__ or method_name.replace(\"_\", \" \").title()\n",
    "        print(f\"   ‚Ä¢ {doc}\")\n",
    "\n",
    "    if len(test_methods) > 5:\n",
    "        print(f\"   ... and {len(test_methods) - 5} more tests\")\n",
    "\n",
    "    print(\"\\nüí° These tests validate edge cases you might not think of!\")\n",
    "    print(\"üí° Much more thorough than manual testing!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è Test suite preview not available yet: {e}\")\n",
    "\n",
    "# Run comprehensive tests\n",
    "run_comprehensive_risk_analyst_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6cdd2",
   "metadata": {},
   "source": [
    "## ‚úÖ Phase 3: Compliance Officer Agent Development\n",
    "\n",
    "The Compliance Officer Agent uses **ReACT prompting** to generate regulatory-compliant SAR narratives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf9061",
   "metadata": {},
   "source": [
    "### üìö Understanding ReACT Prompting\n",
    "\n",
    "ReACT (Reasoning + Action) prompting separates thinking and doing:\n",
    "\n",
    "1. **Reasoning Phase**: Analyze situation and plan approach\n",
    "2. **Action Phase**: Execute specific task with informed decisions\n",
    "3. **Structured Workflow**: Consistent approach to complex tasks\n",
    "4. **Regulatory Compliance**: Emphasis on meeting specific requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test ReACT prompt design\n",
    "# This cell helps you design and test your ReACT prompt structure\n",
    "\n",
    "def design_react_prompt():\n",
    "    \"\"\"Design and test ReACT prompt for compliance narratives\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    TODO: Design your ReACT system prompt here\n",
    "    \n",
    "    Key elements to include:\n",
    "    1. Senior Compliance Officer persona\n",
    "    2. ReACT framework:\n",
    "       REASONING Phase:\n",
    "       - Review risk analyst findings\n",
    "       - Assess regulatory requirements\n",
    "       - Identify compliance elements\n",
    "       - Plan narrative structure\n",
    "       \n",
    "       ACTION Phase:\n",
    "       - Draft concise narrative (‚â§120 words)\n",
    "       - Include specific details\n",
    "       - Reference activity patterns\n",
    "       - Use regulatory language\n",
    "    3. JSON output format specification\n",
    "    \"\"\"\n",
    "    \n",
    "    return system_prompt\n",
    "\n",
    "# Test your prompt design\n",
    "react_prompt = design_react_prompt()\n",
    "print(\"‚ö° ReACT Prompt Design:\")\n",
    "print(react_prompt[:200] + \"...\")\n",
    "print(\"\\nüìã TODO: Complete the prompt in compliance_officer_agent.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement and test Compliance Officer Agent - SIMPLE SMOKE TEST\n",
    "# Students: Write a basic smoke test to verify your agent works\n",
    "\n",
    "# from compliance_officer_agent import ComplianceOfficerAgent\n",
    "\n",
    "def simple_compliance_officer_smoke_test():\n",
    "    \"\"\"\n",
    "    STUDENT TODO: Write a simple smoke test for your Compliance Officer Agent\n",
    "    \n",
    "    This should be a basic test that:\n",
    "    1. Creates a ComplianceOfficerAgent instance\n",
    "    2. Creates simple test case and risk analysis data\n",
    "    3. Calls generate_compliance_narrative() method  \n",
    "    4. Verifies the result has a narrative with reasonable length\n",
    "    5. Prints success/failure\n",
    "    \n",
    "    Keep this simple - just verify your agent doesn't crash and generates text!\n",
    "    \"\"\"\n",
    "    print(\"‚úÖ Compliance Officer Smoke Test\")\n",
    "    print(\"üìã TODO: Import your ComplianceOfficerAgent\")\n",
    "    print(\"üìã TODO: Create agent instance: agent = ComplianceOfficerAgent(client, logger)\")\n",
    "    print(\"üìã TODO: Create simple test case and sample risk analysis\")\n",
    "    print(\"üìã TODO: Call: result = agent.generate_compliance_narrative(case, risk_analysis)\")\n",
    "    print(\"üìã TODO: Verify: result has narrative, word count ‚â§ 120\")\n",
    "    print(\"üìã TODO: Print: 'SUCCESS' or 'FAILED' with details\")\n",
    "    \n",
    "    # Example structure (uncomment and modify when ready):\n",
    "    # try:\n",
    "    #     agent = ComplianceOfficerAgent(client, explainability_logger)\n",
    "    #     # Create test case and risk analysis...\n",
    "    #     result = agent.generate_compliance_narrative(test_case, test_risk_analysis)\n",
    "    #     word_count = len(result.narrative.split())\n",
    "    #     print(f\"‚úÖ SUCCESS: Generated {word_count} word narrative\")\n",
    "    #     print(f\"Preview: {result.narrative[:100]}...\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"‚ùå FAILED: {e}\")\n",
    "\n",
    "simple_compliance_officer_smoke_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d384fc3",
   "metadata": {},
   "source": [
    "### üß™ Compliance Officer Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE Compliance Officer Testing - Import Pre-Built Test Suite\n",
    "# Students: Use our comprehensive test suite instead of writing your own\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add tests directory to Python path for importing test modules (if not already added)\n",
    "project_root = os.path.abspath('..')\n",
    "tests_path = os.path.join(project_root, 'tests')\n",
    "if tests_path not in sys.path:\n",
    "    sys.path.insert(0, tests_path)\n",
    "\n",
    "print(f\"üìÅ Tests directory in Python path: {tests_path}\")\n",
    "\n",
    "def run_comprehensive_compliance_officer_tests():\n",
    "    \"\"\"\n",
    "    Use pre-built comprehensive test suite to validate your Compliance Officer Agent\n",
    "    \n",
    "    These tests validate:\n",
    "    - Agent initialization and configuration\n",
    "    - Narrative generation with valid inputs\n",
    "    - Word count limits (‚â§120 words)\n",
    "    - Regulatory citations inclusion\n",
    "    - JSON parsing and error handling\n",
    "    - ReACT prompt structure validation\n",
    "    \"\"\"\n",
    "    print(\"üß™ Comprehensive Compliance Officer Testing\")\n",
    "    print(\"üìã TODO: Uncomment and run after implementing your Compliance Officer Agent\")\n",
    "    \n",
    "    # Uncomment when your agent is ready:\n",
    "    # try:\n",
    "    #     from test_compliance_officer import TestComplianceOfficerAgent\n",
    "    #     import pytest\n",
    "    #     \n",
    "    #     print(\"\udcdd Loading comprehensive test suite...\")\n",
    "    #     \n",
    "    #     # Run the test suite\n",
    "    #     print(\"üöÄ Running Compliance Officer test suite...\")\n",
    "    #     result = pytest.main([\n",
    "    #         f\"{tests_path}/test_compliance_officer.py\", \n",
    "    #         \"-v\", \n",
    "    #         \"--tb=short\"\n",
    "    #     ])\n",
    "    #     \n",
    "    #     if result == 0:\n",
    "    #         print(\"‚úÖ All Compliance Officer tests passed!\")\n",
    "    #     else:\n",
    "    #         print(\"‚ùå Some tests failed. Check the output above for details.\")\n",
    "    #         \n",
    "    # except ImportError as e:\n",
    "    #     print(f\"‚ùå Import Error: {e}\")\n",
    "    #     print(\"üí° Make sure you've implemented ComplianceOfficerAgent in src/compliance_officer_agent.py\")\n",
    "\n",
    "# Quick preview of available tests\n",
    "try:\n",
    "    from test_compliance_officer import TestComplianceOfficerAgent\n",
    "    import inspect\n",
    "    \n",
    "    # Get all test methods\n",
    "    test_methods = [method for method in dir(TestComplianceOfficerAgent) \n",
    "                   if method.startswith('test_')]\n",
    "    \n",
    "    print(\"üìù Preview of Comprehensive Compliance Officer Tests:\")\n",
    "    for method_name in test_methods[:5]:  # Show first 5\n",
    "        method = getattr(TestComplianceOfficerAgent, method_name)\n",
    "        doc = method.__doc__ or method_name.replace('_', ' ').title()\n",
    "        print(f\"   ‚Ä¢ {doc}\")\n",
    "    if len(test_methods) > 5:\n",
    "        print(f\"   ... and {len(test_methods) - 5} more tests\")\n",
    "    print(\"\\nüí° These tests validate regulatory compliance requirements!\")\n",
    "    print(\"üí° Includes word limits, citations, and required elements!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è Test suite will be available after implementing foundation_sar.py: {e}\")\n",
    "\n",
    "# Call the function\n",
    "run_comprehensive_compliance_officer_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daa86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE AGENT TESTING - Two-Tier Approach\n",
    "# Students: Use this to test both agents together\n",
    "\n",
    "def complete_agent_testing_workflow():\n",
    "    \"\"\"\n",
    "    Complete testing workflow using two-tier approach:\n",
    "    \n",
    "    TIER 1: Simple Smoke Tests (You write these)\n",
    "    - Basic functionality verification\n",
    "    - Quick sanity checks\n",
    "    - Development debugging\n",
    "    \n",
    "    TIER 2: Comprehensive Test Suites (Pre-built for you)\n",
    "    - Complex edge cases\n",
    "    - Regulatory compliance validation\n",
    "    - Professional-grade testing\n",
    "    \"\"\"\n",
    "    print(\"üî¨ Complete Agent Testing Workflow\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüìã TIER 1: Simple Smoke Tests (DO FIRST)\")\n",
    "    print(\"   1. Write simple_risk_analyst_smoke_test() - verify basic functionality\")\n",
    "    print(\"   2. Write simple_compliance_officer_smoke_test() - verify basic functionality\")\n",
    "    print(\"   3. Fix any basic issues before moving to Tier 2\")\n",
    "    \n",
    "    print(\"\\nüß™ TIER 2: Comprehensive Test Suites (DO AFTER TIER 1 PASSES)\")\n",
    "    print(\"   1. Run comprehensive risk analyst test suite (10 comprehensive tests)\")\n",
    "    print(\"   2. Run comprehensive compliance officer test suite (10 comprehensive tests)\")\n",
    "    print(\"   3. Get detailed pass/fail results with specific feedback\")\n",
    "    \n",
    "    print(\"\\nüí° WHY THIS APPROACH?\")\n",
    "    print(\"   ‚úÖ Tier 1: Quick feedback while developing\")\n",
    "    print(\"   ‚úÖ Tier 2: Professional validation without writing complex tests\")\n",
    "    print(\"   ‚úÖ Saves time: You focus on implementation, not test creation\")\n",
    "    print(\"   ‚úÖ Better coverage: Our test suites test edge cases you might miss\")\n",
    "\n",
    "# Quick test runner when both agents are ready\n",
    "def run_both_agents_quick_test():\n",
    "    \"\"\"Quick test of both agents using pre-built test suites\"\"\"\n",
    "    print(\"üöÄ Quick Test of Both Agents\")\n",
    "    print(\"üìã TODO: Uncomment when both agents are implemented\")\n",
    "    \n",
    "    # Uncomment when ready:\n",
    "    # try:\n",
    "    #     import pytest\n",
    "    #     \n",
    "    #     print(\"üîç Running quick tests for both agents...\")\n",
    "    #     \n",
    "    #     # Run a subset of tests for quick validation\n",
    "    #     risk_result = pytest.main([\n",
    "    #         f\"{tests_path}/test_risk_analyst.py::TestRiskAnalystAgent::test_agent_initialization\",\n",
    "    #         f\"{tests_path}/test_risk_analyst.py::TestRiskAnalystAgent::test_analyze_case_success\",\n",
    "    #         \"-v\"\n",
    "    #     ])\n",
    "    #     \n",
    "    #     compliance_result = pytest.main([\n",
    "    #         f\"{tests_path}/test_compliance_officer.py::TestComplianceOfficerAgent::test_agent_initialization\", \n",
    "    #         f\"{tests_path}/test_compliance_officer.py::TestComplianceOfficerAgent::test_generate_compliance_narrative_success\",\n",
    "    #         \"-v\"\n",
    "    #     ])\n",
    "    #     \n",
    "    #     if risk_result == 0 and compliance_result == 0:\n",
    "    #         print(\"üéâ Both agents working! Ready for full test suite testing!\")\n",
    "    #     else:\n",
    "    #         print(\"‚ö†Ô∏è Fix issues before running comprehensive tests\")\n",
    "    #         if risk_result != 0:\n",
    "    #             print(\"   üîç Risk Analyst needs fixes\")\n",
    "    #         if compliance_result != 0:\n",
    "    #             print(\"   üìù Compliance Officer needs fixes\")\n",
    "    #             \n",
    "    # except ImportError as e:\n",
    "    #     print(f\"‚ùå Import Error: {e}\")\n",
    "    #     print(\"üí° Make sure both agents are implemented\")\n",
    "\n",
    "complete_agent_testing_workflow()\n",
    "run_both_agents_quick_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1644f",
   "metadata": {},
   "source": [
    "## üîó Phase 4 Preview: Agent Integration\n",
    "\n",
    "Once both agents are working, you'll integrate them into a complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa545019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Preview of integrated workflow\n",
    "# This will be fully implemented in the next notebook\n",
    "\n",
    "def preview_integrated_workflow():\n",
    "    \"\"\"Preview of how agents will work together\"\"\"\n",
    "    \n",
    "    workflow_steps = [\n",
    "        \"1. üìä Load and validate case data\",\n",
    "        \"2. üîç Risk Analyst performs Chain-of-Thought analysis\",\n",
    "        \"3. üë§ Human review and approval gate\",\n",
    "        \"4. ‚úÖ Compliance Officer generates ReACT narrative (if approved)\",\n",
    "        \"5. üìÑ Generate complete SAR document\",\n",
    "        \"6. üìä Log audit trail and efficiency metrics\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üîó Integrated SAR Processing Workflow:\")\n",
    "    for step in workflow_steps:\n",
    "        print(step)\n",
    "    \n",
    "    print(\"\\nüí° Key Benefits:\")\n",
    "    print(\"‚Ä¢ Two-stage processing reduces AI costs\")\n",
    "    print(\"‚Ä¢ Human oversight ensures regulatory compliance\")\n",
    "    print(\"‚Ä¢ Complete audit trails for examination\")\n",
    "    print(\"‚Ä¢ Standardized analytical approaches\")\n",
    "\n",
    "preview_integrated_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5de9c1",
   "metadata": {},
   "source": [
    "## üìù Development Checklist - Two-Tier Testing Approach\n",
    "\n",
    "### ‚úÖ Risk Analyst Agent (Phase 2)\n",
    "- [X] Implement Chain-of-Thought system prompt\n",
    "- [X] Create `analyze_case` method with error handling\n",
    "- [X] Add JSON parsing and validation\n",
    "- [X] **TIER 1**: Write simple smoke test (verify basic functionality)\n",
    "- [X] **TIER 2**: Run comprehensive pre-built test suite (10 comprehensive tests)\n",
    "- [X] Fix any issues identified by test suite\n",
    "\n",
    "### ‚úÖ Compliance Officer Agent (Phase 3)  \n",
    "- [ ] Implement ReACT system prompt\n",
    "- [ ] Create `generate_compliance_narrative` method\n",
    "- [ ] Add narrative validation (word count, terminology)\n",
    "- [ ] **TIER 1**: Write simple smoke test (verify basic functionality)\n",
    "- [ ] **TIER 2**: Run comprehensive pre-built test suite (10 comprehensive tests)\n",
    "- [ ] Fix any issues identified by test suite\n",
    "\n",
    "### ‚úÖ Testing Strategy Benefits\n",
    "- [ ] **Time Savings**: Focus on implementation, not complex test creation\n",
    "- [ ] **Better Coverage**: Pre-built test suites test edge cases you might miss\n",
    "- [ ] **Quick Feedback**: Simple smoke tests for rapid development cycles\n",
    "- [ ] **Professional Validation**: Comprehensive test suites ensure production readiness\n",
    "- [ ] **Regulatory Compliance**: Built-in checks for SAR requirements\n",
    "\n",
    "### üí° **Testing Workflow**\n",
    "1. **Start with Tier 1**: Write simple smoke tests to verify your agents don't crash\n",
    "2. **Fix basic issues**: Iterate quickly with simple tests during development\n",
    "3. **Move to Tier 2**: Run comprehensive test suites when basic functionality works\n",
    "4. **Analyze results**: Use detailed feedback to improve agent performance\n",
    "5. **Iterate**: Refine prompts and logic based on test results\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Complete Agent Implementation**: Finish both agent classes in the src/ directory\n",
    "2. **Run Two-Tier Testing**: Start with smoke tests, then comprehensive test suites\n",
    "3. **Workflow Integration**: Move to the next notebook for complete system integration\n",
    "4. **Human-in-the-Loop**: Implement decision gates and review processes\n",
    "\n",
    "## üìä Available Test Suites Summary\n",
    "\n",
    "**Risk Analyst Test Suite (10 tests):**\n",
    "- Agent initialization and configuration\n",
    "- Case analysis with valid JSON responses\n",
    "- JSON parsing and error handling\n",
    "- System prompt structure validation\n",
    "- API call parameter verification\n",
    "- Helper method functionality\n",
    "- Edge case handling\n",
    "\n",
    "**Compliance Officer Test Suite (10 tests):**\n",
    "- Agent initialization and configuration\n",
    "- Narrative generation with valid responses\n",
    "- Word count validation (‚â§120 words)\n",
    "- Regulatory citations inclusion\n",
    "- JSON parsing and error handling\n",
    "- ReACT prompt structure validation\n",
    "- API call parameter verification\n",
    "\n",
    "**Ready to build intelligent agents with professional-grade testing! üïµÔ∏è‚Äç‚ôÄÔ∏è**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
