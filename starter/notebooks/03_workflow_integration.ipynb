{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8109ccdb",
   "metadata": {},
   "source": [
    "# üîó Workflow Integration - Complete SAR Processing System\n",
    "\n",
    "Welcome to Phase 4 of the Financial Services Agentic AI Project!\n",
    "\n",
    "In this notebook, you'll integrate both AI agents into a complete **end-to-end SAR processing workflow** that demonstrates real-world financial compliance automation.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Build a complete two-stage AI workflow with human oversight\n",
    "- Implement human-in-the-loop decision gates for compliance\n",
    "- Generate complete SAR documents from AI analysis\n",
    "- Create comprehensive audit trails for regulatory examination\n",
    "- Demonstrate cost optimization through intelligent agent coordination\n",
    "\n",
    "## üìã Business Context\n",
    "This workflow simulates how banks actually process suspicious activity reports:\n",
    "1. **Risk Screening**: AI agents analyze transaction patterns for suspicious activity\n",
    "2. **Human Review**: Compliance officers review AI findings before proceeding\n",
    "3. **Narrative Generation**: Only approved cases get full compliance documentation\n",
    "4. **SAR Filing**: Complete regulatory forms are generated for submission\n",
    "5. **Audit Documentation**: Every decision is logged for regulatory examination\n",
    "\n",
    "## üèóÔ∏è System Architecture\n",
    "\n",
    "```\n",
    "üìä CSV Data ‚Üí üîç Risk Analyst ‚Üí üë§ Human Decision ‚Üí ‚úÖ Compliance Officer ‚Üí üìÑ SAR Document\n",
    "              (Chain-of-Thought)    (Gate)         (ReACT Framework)     (FinCEN Ready)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a422335",
   "metadata": {},
   "source": [
    "## üöÄ Prerequisites Check\n",
    "\n",
    "Before starting, ensure you have completed:\n",
    "- ‚úÖ Phase 1: Foundation components (`foundation_sar.py`)\n",
    "- ‚úÖ Phase 2: Risk Analyst Agent (`risk_analyst_agent.py`)\n",
    "- ‚úÖ Phase 3: Compliance Officer Agent (`compliance_officer_agent.py`)\n",
    "- ‚úÖ Both agents pass their comprehensive test scenarios\n",
    "\n",
    "If any component is missing, return to previous notebooks to complete implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9b3e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Libraries imported successfully!\n",
      "üîê Environment variables loaded\n",
      "üìÇ Source directory added to Python path\n"
     ]
    }
   ],
   "source": [
    "# Setup and Environment Configuration\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add src directory to Python path for module imports\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(\"üîê Environment variables loaded\")\n",
    "print(\"üìÇ Source directory added to Python path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54cba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized with Vocareum routing\n",
      "üîë API key: sk-proj-...x7IA\n",
      "üìç Base URL: https://openai.vocareum.com/v1\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Setup for Vocareum\n",
    "import openai\n",
    "\n",
    "# Initialize OpenAI client for Vocareum\n",
    "openai_api_key = os.getenv('OPENAI_VOCAREUM_API_KEY')\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"‚ö†Ô∏è WARNING: No OpenAI API key found!\")\n",
    "    print(\"Please set OPENAI_API_KEY in your .env file\")\n",
    "    print(\"Get your Vocareum OpenAI API key from 'Cloud Resources' in your workspace\")\n",
    "else:\n",
    "    # Vocareum requires routing through their servers\n",
    "    client = openai.OpenAI(\n",
    "        base_url=\"https://openai.vocareum.com/v1\",\n",
    "        api_key=openai_api_key\n",
    "    )\n",
    "    print(\"‚úÖ OpenAI client initialized with Vocareum routing\")\n",
    "    print(f\"üîë API key: {openai_api_key[:8]}...{openai_api_key[-4:]}\")\n",
    "    print(\"üìç Base URL: https://openai.vocareum.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e78bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã TODO: Import your implemented components\n",
      "Uncomment and modify these imports once you've implemented all components:\n",
      "‚úÖ Ready to import components after implementation\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import Your Implemented Components\n",
    "# Students: Import your foundation components and agents\n",
    "\n",
    "print(\"üìã TODO: Import your implemented components\")\n",
    "print(\"Uncomment and modify these imports once you've implemented all components:\")\n",
    "\n",
    "from foundation_sar import (\n",
    "     CustomerData,\n",
    "     AccountData,\n",
    "     TransactionData,\n",
    "     CaseData,\n",
    "     RiskAnalystOutput,\n",
    "     ComplianceOfficerOutput,\n",
    "     ExplainabilityLogger,\n",
    "     DataLoader,\n",
    "     load_csv_data\n",
    ")\n",
    "from risk_analyst_agent import RiskAnalystAgent\n",
    "from compliance_officer_agent import ComplianceOfficerAgent\n",
    "\n",
    "# TODO: Create agent instances\n",
    "explainability_logger = ExplainabilityLogger(\"../outputs/audit_logs/workflow_integration.jsonl\")\n",
    "risk_agent = RiskAnalystAgent(client, explainability_logger)\n",
    "compliance_agent = ComplianceOfficerAgent(client, explainability_logger)\n",
    "\n",
    "print(\"‚úÖ Ready to import components after implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d3cdab",
   "metadata": {},
   "source": [
    "## üìä Step 1: Data Loading and Preprocessing\n",
    "\n",
    "Load the financial data and prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading Financial Data...\n",
      "üìà Loaded: 150 customers, 178 accounts, 4268 transactions\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load and Preprocess Financial Data\n",
    "# Students: Load customer, account, and transaction data\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    It loads CSV data, handles null values, and converts them to dictionaries.\n",
    "    \"\"\"\n",
    "    print(\"üìä Loading Financial Data...\")\n",
    "    \n",
    "    try:\n",
    "        # Load using pandas\n",
    "        customers_df = pd.read_csv(\"../data/customers.csv\", dtype={'ssn_last_4': str})\n",
    "        accounts_df = pd.read_csv(\"../data/accounts.csv\")\n",
    "        transactions_df = pd.read_csv(\"../data/transactions.csv\")\n",
    "        \n",
    "        # Handling NaNs (Pydantic validator 'blank_to_none' helps, but it's good to be sure)\n",
    "        customers_df = customers_df.fillna('')\n",
    "        # Converts numeric columns that may have come as string/NaN.\n",
    "        customers_df['annual_income'] = pd.to_numeric(customers_df['annual_income'], errors='coerce').fillna(0.0)\n",
    "        \n",
    "        # Accounts\n",
    "        accounts_df = accounts_df.fillna('')\n",
    "        accounts_df['current_balance'] = pd.to_numeric(accounts_df['current_balance'], errors='coerce').fillna(0.0)\n",
    "        accounts_df['average_monthly_balance'] = pd.to_numeric(accounts_df['average_monthly_balance'], errors='coerce').fillna(0.0)\n",
    "\n",
    "        # Transactions\n",
    "        transactions_df = transactions_df.fillna('')\n",
    "        transactions_df['amount'] = pd.to_numeric(transactions_df['amount'], errors='coerce').fillna(0.0)\n",
    "        \n",
    "        # Convert DataFrames to list of dicts\n",
    "        customers_data = customers_df.to_dict('records')\n",
    "        accounts_data = accounts_df.to_dict('records')\n",
    "        transactions_data = transactions_df.to_dict('records')\n",
    "        \n",
    "        print(f\"üìà Loaded: {len(customers_data)} customers, {len(accounts_data)} accounts, {len(transactions_data)} transactions\")\n",
    "        return customers_data, accounts_data, transactions_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar dados: {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "# Load data\n",
    "customers_data, accounts_data, transactions_data = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90084977",
   "metadata": {},
   "source": [
    "## üéØ Step 2: Customer Risk Screening\n",
    "\n",
    "Implement intelligent customer screening to identify high-risk cases for detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d82ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Customer Risk Screening...\n",
      "üìä Selected 5 high-risk customers for detailed AI analysis.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement Customer Risk Screening\n",
    "# Students: Create risk-based customer screening logic\n",
    "\n",
    "def screen_high_risk_customers(customers_data, accounts_data, transactions_data, top_n=5):\n",
    "    \"\"\"\n",
    "    Filtra clientes de alto risco baseados em regras determin√≠sticas.\n",
    "    \"\"\"\n",
    "    print(\"üîç Customer Risk Screening...\")\n",
    "    selected_customers = []\n",
    "    \n",
    "    for customer in customers_data:\n",
    "        c_id = customer['customer_id']\n",
    "        \n",
    "        # 1. Aggregates customer accounts\n",
    "        cust_accounts = [acc for acc in accounts_data if acc['customer_id'] == c_id]\n",
    "        acc_ids = {acc['account_id'] for acc in cust_accounts}\n",
    "        \n",
    "        # 2. Aggregates transactions from accounts\n",
    "        cust_txns = [txn for txn in transactions_data if txn['account_id'] in acc_ids]\n",
    "        \n",
    "        # 3. Calculates risk indicators\n",
    "        total_amount = sum(abs(t['amount']) for t in cust_txns)\n",
    "        txn_count = len(cust_txns)\n",
    "        risk_rating = customer.get('risk_rating', 'Low')\n",
    "        \n",
    "        risk_flags = []\n",
    "        \n",
    "        # Screening Rules\n",
    "        if risk_rating in ['High', 'Medium']:\n",
    "            risk_flags.append('high_risk_rating')\n",
    "        if total_amount > 100000:\n",
    "            risk_flags.append('large_volume')\n",
    "        if txn_count > 50:\n",
    "            risk_flags.append('high_frequency')\n",
    "        \n",
    "        # If there's at least 1 flag (i.e., it's worth the AI to analyze), add to list\n",
    "        if len(risk_flags) >= 1:\n",
    "            selected_customers.append({\n",
    "                'customer': customer,\n",
    "                'accounts': cust_accounts,\n",
    "                'transactions': cust_txns,\n",
    "                'score_metrics': {\n",
    "                    'total_amount': total_amount,\n",
    "                    'flags': risk_flags\n",
    "                }\n",
    "            })\n",
    "            \n",
    "    # Sorts: Prioritize those with more flags and higher financial volume\n",
    "    selected_customers.sort(\n",
    "        key=lambda x: (len(x['score_metrics']['flags']), x['score_metrics']['total_amount']), \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    final_selection = selected_customers[:top_n]\n",
    "    print(f\"üìä Selected {len(final_selection)} high-risk customers for detailed AI analysis.\")\n",
    "    return final_selection\n",
    "\n",
    "# Execute the screening\n",
    "selected_customers = screen_high_risk_customers(customers_data, accounts_data, transactions_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ffbca",
   "metadata": {},
   "source": [
    "## ü§ñ Step 3: Two-Stage AI Analysis with Human Gates\n",
    "\n",
    "Implement the core two-stage workflow:\n",
    "1. **Stage 1**: Risk Analyst performs Chain-of-Thought analysis\n",
    "2. **Human Gate**: Review and decision to proceed\n",
    "3. **Stage 2**: Compliance Officer generates ReACT narratives (only if approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Two-Stage AI Workflow\n",
    "# Students: Build the complete workflow with human decision gates\n",
    "\n",
    "def run_two_stage_sar_workflow(selected_customers):\n",
    "    print(\"ü§ñ Starting Two-Stage SAR Processing Workflow...\")\n",
    "    \n",
    "    processed_cases = []\n",
    "    approved_sars = []\n",
    "    rejected_cases = []\n",
    "    audit_decisions = []\n",
    "    \n",
    "    loader = DataLoader(explainability_logger)\n",
    "\n",
    "    for i, customer_bundle in enumerate(selected_customers, 1):\n",
    "        cust_data = customer_bundle['customer']\n",
    "        print(f\"\\n[{i}/{len(selected_customers)}] Processing Customer: {cust_data['name']} (ID: {cust_data['customer_id']})\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            # 1. Create a CaseData object (unifying the data)\n",
    "            case_data = loader.create_case_from_data(\n",
    "                cust_data,\n",
    "                customer_bundle['accounts'],\n",
    "                customer_bundle['transactions']\n",
    "            )\n",
    "            processed_cases.append(case_data)\n",
    "            \n",
    "            # ---------------------------------------------------------\n",
    "            # STAGE 1: Risk Analysis (Chain-of-Thought)\n",
    "            # ---------------------------------------------------------\n",
    "            print(\"üîç Running Risk Analyst Agent...\")\n",
    "            risk_analysis = risk_agent.analyze_case(case_data)\n",
    "            \n",
    "            # Displays results for Humans\n",
    "            print(f\"\\n--- AI FINDINGS ---\")\n",
    "            print(f\"Classification: {risk_analysis.classification}\")\n",
    "            print(f\"Risk Level:     {risk_analysis.risk_level}\")\n",
    "            print(f\"Confidence:     {risk_analysis.confidence_score:.2f}\")\n",
    "            print(f\"Reasoning:      {risk_analysis.reasoning[:150]}...\")\n",
    "            \n",
    "            # ---------------------------------------------------------\n",
    "            # HUMAN DECISION GATE\n",
    "            # ---------------------------------------------------------\n",
    "            # Note: In production, this would be a web interface. Here we use input().\n",
    "            # If the score is too low, we could auto-reject, but the prompt asks for human decision.\n",
    "            \n",
    "            decision = input(\">>> Proceed with SAR filing? (yes/no): \").strip().lower()\n",
    "            should_proceed = decision in ['yes', 'y']\n",
    "            \n",
    "            if should_proceed:\n",
    "                print(\"‚úÖ Approved. Proceeding to Compliance Narrative generation.\")\n",
    "                \n",
    "                # -----------------------------------------------------\n",
    "                # STAGE 2: Compliance Officer (ReACT)\n",
    "                # -----------------------------------------------------\n",
    "                compliance_review = compliance_agent.generate_compliance_narrative(case_data, risk_analysis)\n",
    "                \n",
    "                # Generates Final SAR Document\n",
    "                sar_document = create_sar_document(case_data, risk_analysis, compliance_review)\n",
    "                save_sar_document(sar_document)\n",
    "                \n",
    "                approved_sars.append(sar_document)\n",
    "                print(f\"üìÑ SAR Generated: {sar_document['sar_metadata']['sar_id']}\")\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå Rejected by human reviewer.\")\n",
    "                rejected_cases.append({\n",
    "                    'case_id': case_data.case_id,\n",
    "                    'reason': 'Human Rejection'\n",
    "                })\n",
    "\n",
    "            # Log for Audit\n",
    "            audit_decisions.append({\n",
    "                'case_id': case_data.case_id,\n",
    "                'customer_name': cust_data['name'],\n",
    "                'ai_risk_level': risk_analysis.risk_level,\n",
    "                'human_decision': 'APPROVED' if should_proceed else 'REJECTED',\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing case: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    return processed_cases, approved_sars, rejected_cases, audit_decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43730f",
   "metadata": {},
   "source": [
    "## üìÑ Step 4: SAR Document Generation\n",
    "\n",
    "Create complete, FinCEN-ready SAR documents with all required metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Fun√ß√µes de gera√ß√£o de SAR definidas.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement SAR Document Generation\n",
    "# Students: Create complete SAR documents for regulatory submission\n",
    "\n",
    "def create_sar_document(case_data, risk_analysis, compliance_review):\n",
    "    \"\"\"\n",
    "    Cria o documento JSON final do SAR combinando todas as sa√≠das.\n",
    "    \"\"\"\n",
    "    sar_id = f\"SAR-{uuid.uuid4().hex[:8].upper()}\"\n",
    "    filing_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    sar_doc = {\n",
    "        \"sar_metadata\": {\n",
    "            \"sar_id\": sar_id,\n",
    "            \"filing_date\": filing_date,\n",
    "            \"filing_type\": \"Initial\",\n",
    "            \"fincen_form_type\": \"111\",\n",
    "            \"status\": \"Ready for Submission\"\n",
    "        },\n",
    "        \"subject_information\": {\n",
    "            \"name\": case_data.customer.name,\n",
    "            \"ssn_last_4\": case_data.customer.ssn_last_4,\n",
    "            \"address\": case_data.customer.address,\n",
    "            \"occupation\": getattr(case_data.customer, 'occupation', 'Unknown'),\n",
    "            \"birth_date\": case_data.customer.date_of_birth\n",
    "        },\n",
    "        \"suspicious_activity\": {\n",
    "            \"classification\": risk_analysis.classification,\n",
    "            \"date_range_start\": min([t.transaction_date for t in case_data.transactions], default=\"\"),\n",
    "            \"date_range_end\": max([t.transaction_date for t in case_data.transactions], default=\"\"),\n",
    "            \"total_amount\": sum([t.amount for t in case_data.transactions]),\n",
    "            \"key_indicators\": risk_analysis.key_indicators\n",
    "        },\n",
    "        \"narrative\": {\n",
    "            \"text\": compliance_review.narrative,\n",
    "            \"reasoning\": compliance_review.narrative_reasoning,\n",
    "            \"regulatory_citations\": compliance_review.regulatory_citations,\n",
    "            \"word_count\": len(compliance_review.narrative.split())\n",
    "        }\n",
    "    }\n",
    "    return sar_doc\n",
    "\n",
    "def save_sar_document(sar_document):\n",
    "    \"\"\"Salva o SAR em disco.\"\"\"\n",
    "    output_dir = \"../outputs/filed_sars\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    filename = f\"{output_dir}/{sar_document['sar_metadata']['sar_id']}.json\"\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(sar_document, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # print(f\"üíæ Saved to {filename}\")\n",
    "\n",
    "print(\"üìÑ Fun√ß√µes de gera√ß√£o de SAR definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34499e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Starting Two-Stage SAR Processing Workflow...\n",
      "\n",
      "[1/5] Processing Customer: Jacqueline Rodriguez (ID: CUST_0111)\n",
      "============================================================\n",
      "üîç Running Risk Analyst Agent...\n",
      "\n",
      "--- AI FINDINGS ---\n",
      "Classification: Money_Laundering\n",
      "Risk Level:     High\n",
      "Confidence:     0.85\n",
      "Reasoning:      The customer has a high risk rating and is involved in high volume and high value transactions, including large incoming and outgoing wire transfers. ...\n",
      "‚úÖ Approved. Proceeding to Compliance Narrative generation.\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "üìÑ SAR Generated: SAR-CFAA9F63\n",
      "\n",
      "[2/5] Processing Customer: Michael Stanley (ID: CUST_0062)\n",
      "============================================================\n",
      "üîç Running Risk Analyst Agent...\n",
      "\n",
      "--- AI FINDINGS ---\n",
      "Classification: Money_Laundering\n",
      "Risk Level:     High\n",
      "Confidence:     0.90\n",
      "Reasoning:      The customer has a medium risk rating and has been involved in a series of large, rapid, and unusual wire transfers. This includes a large incoming wi...\n",
      "‚úÖ Approved. Proceeding to Compliance Narrative generation.\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "üìÑ SAR Generated: SAR-B0657A4A\n",
      "\n",
      "[3/5] Processing Customer: Cindy Clayton (ID: CUST_0057)\n",
      "============================================================\n",
      "üîç Running Risk Analyst Agent...\n",
      "\n",
      "--- AI FINDINGS ---\n",
      "Classification: Structuring\n",
      "Risk Level:     High\n",
      "Confidence:     0.85\n",
      "Reasoning:      The customer's account shows a pattern of large ATM withdrawals and deposits close to each other in terms of date and location. This could be an attem...\n",
      "‚úÖ Approved. Proceeding to Compliance Narrative generation.\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "üìÑ SAR Generated: SAR-81D45B39\n",
      "\n",
      "[4/5] Processing Customer: Tracy Lewis (ID: CUST_0053)\n",
      "============================================================\n",
      "üîç Running Risk Analyst Agent...\n",
      "\n",
      "--- AI FINDINGS ---\n",
      "Classification: Structuring\n",
      "Risk Level:     High\n",
      "Confidence:     0.90\n",
      "Reasoning:      The customer has made multiple cash deposits just below the $10,000 reporting threshold in a short period of time. This is a common structuring techni...\n",
      "‚úÖ Approved. Proceeding to Compliance Narrative generation.\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "üìÑ SAR Generated: SAR-AE3C4794\n",
      "\n",
      "[5/5] Processing Customer: Patrick Williams (ID: CUST_0118)\n",
      "============================================================\n",
      "üîç Running Risk Analyst Agent...\n",
      "\n",
      "--- AI FINDINGS ---\n",
      "Classification: Structuring\n",
      "Risk Level:     High\n",
      "Confidence:     0.85\n",
      "Reasoning:      The customer has made multiple cash deposits and withdrawals in quick succession, often on the same day, which is a common structuring technique to av...\n",
      "‚úÖ Approved. Proceeding to Compliance Narrative generation.\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "üìÑ SAR Generated: SAR-97C68EE1\n"
     ]
    }
   ],
   "source": [
    "processed_cases, approved_sars, rejected_cases, audit_decisions = run_two_stage_sar_workflow(selected_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0a8aa",
   "metadata": {},
   "source": [
    "## üìä Step 5: Workflow Metrics and Analysis\n",
    "\n",
    "Analyze the efficiency and effectiveness of your AI-powered SAR processing system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d20db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä WORKFLOW EFFICIENCY REPORT\n",
      "========================================\n",
      "Total Cases Screened (AI Stage 1): 5\n",
      "Human Approved (Proceeded to Stage 2): 5\n",
      "Human Rejected (Stopped at Stage 1): 0\n",
      "Approval Rate: 100.0%\n",
      "\n",
      "üí∞ COST OPTIMIZATION\n",
      "Actual API Cost (Two-Stage): $1.00\n",
      "Theoretical Cost (Single-Stage): $1.00\n",
      "Savings Generated: $0.00 (0.0%)\n",
      "\n",
      "ü§ñ AI ACCURACY SNAPSHOT\n",
      "ai_risk_level  human_decision\n",
      "High           APPROVED          5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement Workflow Analysis and Metrics\n",
    "# Students: Calculate efficiency metrics and cost analysis\n",
    "\n",
    "def analyze_workflow_efficiency(processed_cases, approved_sars, rejected_cases, audit_decisions):\n",
    "    print(\"\\nüìä WORKFLOW EFFICIENCY REPORT\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    total = len(processed_cases)\n",
    "    if total == 0:\n",
    "        print(\"No cases processed.\")\n",
    "        return\n",
    "\n",
    "    approved = len(approved_sars)\n",
    "    rejected = len(rejected_cases)\n",
    "    \n",
    "    print(f\"Total Cases Screened (AI Stage 1): {total}\")\n",
    "    print(f\"Human Approved (Proceeded to Stage 2): {approved}\")\n",
    "    print(f\"Human Rejected (Stopped at Stage 1): {rejected}\")\n",
    "    \n",
    "    approval_rate = (approved / total) * 100\n",
    "    print(f\"Approval Rate: {approval_rate:.1f}%\")\n",
    "    \n",
    "    # Cost Estimation\n",
    "    # Assuming: Stage 1 = $0.05, Stage 2 = $0.15 (due to larger/more complex output)\n",
    "    cost_stage_1 = total * 0.05\n",
    "    cost_stage_2 = approved * 0.15\n",
    "    total_cost = cost_stage_1 + cost_stage_2\n",
    "    \n",
    "    # Cost if we ran everything in single-stage (all generate narrative)\n",
    "    theoretical_cost = total * (0.05 + 0.15)\n",
    "    savings = theoretical_cost - total_cost\n",
    "    \n",
    "    print(f\"\\nüí∞ COST OPTIMIZATION\")\n",
    "    print(f\"Actual API Cost (Two-Stage): ${total_cost:.2f}\")\n",
    "    print(f\"Theoretical Cost (Single-Stage): ${theoretical_cost:.2f}\")\n",
    "    print(f\"Savings Generated: ${savings:.2f} ({(savings/theoretical_cost)*100:.1f}%)\")\n",
    "\n",
    "def validate_ai_decisions(audit_decisions):\n",
    "    print(\"\\nü§ñ AI ACCURACY SNAPSHOT\")\n",
    "    # Simple analysis of decision logs\n",
    "    df = pd.DataFrame(audit_decisions)\n",
    "    if not df.empty:\n",
    "        print(df.groupby(['ai_risk_level', 'human_decision']).size())\n",
    "\n",
    "# Execute the metrics\n",
    "analyze_workflow_efficiency(processed_cases, approved_sars, rejected_cases, audit_decisions)\n",
    "validate_ai_decisions(audit_decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd3e82b",
   "metadata": {},
   "source": [
    "## üèÅ Step 6: Complete System Demonstration\n",
    "\n",
    "Test your complete system with comprehensive scenarios to validate production readiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ DEMONSTRATION MODE INITIALIZED\n",
      "üìä Loading Financial Data...\n",
      "üìà Loaded: 150 customers, 178 accounts, 4268 transactions\n",
      "üîç Customer Risk Screening...\n",
      "üìä Selected 3 high-risk customers for detailed AI analysis.\n",
      "\n",
      "--- Processing Batch ---\n",
      "ü§ñ Starting Two-Stage SAR Processing Workflow...\n",
      "\n",
      "[1/3] Processing Customer: Jacqueline Rodriguez (ID: CUST_0111)\n",
      "============================================================\n",
      "üîç Running Risk Analyst Agent...\n",
      "‚ùå Error processing case: Failed to parse Risk Analyst JSON output\n",
      "\n",
      "[2/3] Processing Customer: Michael Stanley (ID: CUST_0062)\n",
      "============================================================\n",
      "üîç Running Risk Analyst Agent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\\src\\risk_analyst_agent.py\", line 216, in analyze_case\n",
      "    result = RiskAnalystOutput(\n",
      "  File \"C:\\Users\\eduar\\AppData\\Roaming\\Python\\Python310\\site-packages\\pydantic\\main.py\", line 250, in __init__\n",
      "    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "pydantic_core._pydantic_core.ValidationError: 1 validation error for RiskAnalystOutput\n",
      "classification\n",
      "  Input should be 'Structuring', 'Sanctions', 'Fraud', 'Money_Laundering' or 'Other' [type=literal_error, input_value='Money_Laudering', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/literal_error\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_32904\\1829394876.py\", line 32, in run_two_stage_sar_workflow\n",
      "    risk_analysis = risk_agent.analyze_case(case_data)\n",
      "  File \"c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\\src\\risk_analyst_agent.py\", line 237, in analyze_case\n",
      "    raise ValueError(\"Failed to parse Risk Analyst JSON output\")\n",
      "ValueError: Failed to parse Risk Analyst JSON output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AI FINDINGS ---\n",
      "Classification: Money_Laundering\n",
      "Risk Level:     High\n",
      "Confidence:     0.85\n",
      "Reasoning:      The customer has a medium risk rating and has performed a large incoming wire transfer followed by multiple outgoing wire transfers in a short period ...\n",
      "‚úÖ Approved. Proceeding to Compliance Narrative generation.\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "üìÑ SAR Generated: SAR-F43A4ED8\n",
      "\n",
      "[3/3] Processing Customer: Cindy Clayton (ID: CUST_0057)\n",
      "============================================================\n",
      "üîç Running Risk Analyst Agent...\n",
      "\n",
      "--- AI FINDINGS ---\n",
      "Classification: Structuring\n",
      "Risk Level:     High\n",
      "Confidence:     0.85\n",
      "Reasoning:      The customer has a high risk rating and has been involved in numerous transactions, many of which are close to the $5,000 threshold. This suggests a p...\n",
      "‚úÖ Approved. Proceeding to Compliance Narrative generation.\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "üìÑ SAR Generated: SAR-1933A29A\n",
      "\n",
      "üìä WORKFLOW EFFICIENCY REPORT\n",
      "========================================\n",
      "Total Cases Screened (AI Stage 1): 3\n",
      "Human Approved (Proceeded to Stage 2): 2\n",
      "Human Rejected (Stopped at Stage 1): 0\n",
      "Approval Rate: 66.7%\n",
      "\n",
      "üí∞ COST OPTIMIZATION\n",
      "Actual API Cost (Two-Stage): $0.45\n",
      "Theoretical Cost (Single-Stage): $0.60\n",
      "Savings Generated: $0.15 (25.0%)\n",
      "\n",
      "üèÅ System Demonstration Complete.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run Complete System Test\n",
    "# Students: Demonstrate your complete SAR processing system\n",
    "\n",
    "def demonstrate_complete_system():\n",
    "    print(\"üöÄ DEMONSTRATION MODE INITIALIZED\")\n",
    "    \n",
    "    # 1. Load\n",
    "    c, a, t = load_and_preprocess_data()\n",
    "    \n",
    "    # 2. Screening (Grab top 3 for quick demo)\n",
    "    selected = screen_high_risk_customers(c, a, t, top_n=3)\n",
    "    \n",
    "    if not selected:\n",
    "        print(\"‚ö†Ô∏è Nenhum cliente selecionado para demonstra√ß√£o.\")\n",
    "        return\n",
    "\n",
    "    # 3. Execute\n",
    "    print(\"\\n--- Processing Batch ---\")\n",
    "    p, app, rej, audit = run_two_stage_sar_workflow(selected)\n",
    "    \n",
    "    # 4. Report\n",
    "    analyze_workflow_efficiency(p, app, rej, audit)\n",
    "    \n",
    "    print(\"\\nüèÅ System Demonstration Complete.\")\n",
    "\n",
    "# Execute Demo\n",
    "demonstrate_complete_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f5f95",
   "metadata": {},
   "source": [
    "## üìù Implementation Checklist\n",
    "\n",
    "### ‚úÖ Workflow Integration Deliverables\n",
    "- [X] **Data Loading**: Load and preprocess CSV data with proper error handling\n",
    "- [X] **Customer Screening**: Implement risk-based screening to identify high-risk cases\n",
    "- [X] **Two-Stage Workflow**: Build complete Risk Analyst ‚Üí Human Gate ‚Üí Compliance Officer flow\n",
    "- [X] **Human Decision Gates**: Implement interactive approval/rejection points\n",
    "- [X] **SAR Document Generation**: Create complete FinCEN-ready documents with metadata\n",
    "- [X] **Audit Trail Creation**: Log all decisions and reasoning for regulatory examination\n",
    "- [X] **Efficiency Metrics**: Calculate cost optimization and processing efficiency\n",
    "- [X] **System Demonstration**: Test complete workflow with multiple scenarios\n",
    "\n",
    "### ‚úÖ Testing and Validation Requirements\n",
    "- [X] **Component Validation**: Verify all foundation components and agents are available\n",
    "- [X] **Integration Testing**: Run comprehensive test suites for all components with proper sys.path setup\n",
    "- [X] **End-to-End Testing**: Test complete workflow with automated scenarios\n",
    "- [X] **Error Handling Testing**: Validate graceful handling of edge cases and failures\n",
    "- [X] **Output Validation**: Ensure SAR documents meet regulatory standards\n",
    "- [X] **Performance Testing**: Measure workflow efficiency and processing times\n",
    "\n",
    "### ‚úÖ Technical Requirements\n",
    "- [X] **Error Handling**: Robust exception handling for all workflow steps\n",
    "- [X] **Data Validation**: Proper validation of all inputs and outputs\n",
    "- [X] **File Management**: Organize outputs in appropriate directories\n",
    "- [X] **Logging**: Comprehensive audit logging for compliance\n",
    "- [X] **Performance**: Efficient processing of multiple cases\n",
    "- [X] **User Experience**: Clear prompts and feedback for human reviewers\n",
    "- [X] **Test Infrastructure**: Proper test imports and sys.path configuration\n",
    "\n",
    "### ‚úÖ Business Requirements  \n",
    "- [X] **Regulatory Compliance**: Ensure all SAR documents meet FinCEN requirements\n",
    "- [X] **Cost Optimization**: Demonstrate savings from two-stage processing\n",
    "- [X] **Audit Readiness**: Create examination-ready documentation\n",
    "- [X] **Quality Assurance**: Validate AI decisions with human oversight\n",
    "- [X] **Scalability**: Design for processing larger datasets\n",
    "- [X] **Production Readiness**: Complete testing validates system reliability\n",
    "\n",
    "## üéØ Success Criteria\n",
    "\n",
    "By completion, your integrated system should:\n",
    "- ‚úÖ Process real financial data with proper validation\n",
    "- ‚úÖ Execute complete two-stage AI workflow with human gates\n",
    "- ‚úÖ Generate regulatory-compliant SAR documents\n",
    "- ‚úÖ Create comprehensive audit trails for all decisions\n",
    "- ‚úÖ Demonstrate measurable cost optimization benefits\n",
    "- ‚úÖ Handle errors gracefully and provide clear user feedback\n",
    "- ‚úÖ Pass all integration and end-to-end tests\n",
    "- ‚úÖ Meet production-ready quality standards\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Complete Implementation**: Fill in all TODO sections with working code\n",
    "2. **Run Integration Tests**: Validate all components work together properly\n",
    "3. **Execute End-to-End Tests**: Test complete workflow with automated scenarios\n",
    "4. **Test Thoroughly**: Run complete workflow with various manual scenarios\n",
    "5. **Validate Outputs**: Ensure SAR documents meet regulatory requirements\n",
    "6. **Document Results**: Create final project documentation and metrics\n",
    "7. **Prepare Presentation**: Demonstrate your system's capabilities and business value\n",
    "\n",
    "**Congratulations on building a complete AI-powered SAR processing system! üéâ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c477af2",
   "metadata": {},
   "source": [
    "## üß™ Step 7: Workflow Testing and Validation\n",
    "\n",
    "Before finalizing your implementation, validate your complete system with comprehensive testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981a57d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Added tests directory to Python path: c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\\tests\n",
      "üîç Validating Workflow Components\n",
      "‚úÖ Foundation components available\n",
      "‚úÖ Risk Analyst Agent available\n",
      "‚úÖ Compliance Officer Agent available\n",
      "‚úÖ Test modules available\n",
      "\n",
      "üìä Component Status: ‚úÖ ALL READY\n",
      "\n",
      "üöÄ All components ready - you can run integration tests!\n",
      "üß™ Comprehensive Integration Testing\n",
      "üìã TODO: Uncomment and run after implementing complete workflow\n",
      "üîç Running Foundation Component Tests...\n",
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.10.11, pytest-9.0.2, pluggy-1.6.0 -- c:\\Program Files\\Python310\\python.exe\n",
      "rootdir: c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\n",
      "plugins: anyio-4.11.0, langsmith-0.4.42\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 10 items\n",
      "\n",
      "..\\tests\\test_foundation.py::TestCustomerData::test_valid_customer_data \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestCustomerData::test_customer_risk_rating_validation \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestAccountData::test_valid_account_data \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestAccountData::test_account_balance_validation \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestTransactionData::test_valid_transaction_data \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestTransactionData::test_transaction_amount_validation \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestCaseData::test_valid_case_creation \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestDataLoader::test_csv_data_loading \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestExplainabilityLogger::test_log_creation \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "..\\tests\\test_foundation.py::TestExplainabilityLogger::test_log_file_writing \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m10 passed\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "üîç Running Risk Analyst Agent Tests...\n",
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.10.11, pytest-9.0.2, pluggy-1.6.0 -- c:\\Program Files\\Python310\\python.exe\n",
      "rootdir: c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\n",
      "plugins: anyio-4.11.0, langsmith-0.4.42\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 10 items\n",
      "\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_agent_initialization \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_analyze_case_success \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_analyze_case_json_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_extract_json_from_code_block \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_extract_json_from_plain_text \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_extract_json_empty_response \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_format_accounts \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_format_transactions \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_system_prompt_structure \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "..\\tests\\test_risk_analyst.py::TestRiskAnalystAgent::test_api_call_parameters \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m10 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "üìù Running Compliance Officer Agent Tests...\n",
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.10.11, pytest-9.0.2, pluggy-1.6.0 -- c:\\Program Files\\Python310\\python.exe\n",
      "rootdir: c:\\Projects\\Agentic AI For Financial Services\\1. Prompting for LLM Reasoning and Planning for Financial Services\\Project - Automated SAR Detection & Reporting System\\starter\n",
      "plugins: anyio-4.11.0, langsmith-0.4.42\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 10 items\n",
      "\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_agent_initialization \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_generate_compliance_narrative_success \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_narrative_word_count_validation \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_json_parsing_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_extract_json_from_code_block \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_extract_json_from_plain_text \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_extract_json_empty_response \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_format_transactions_for_compliance \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_system_prompt_structure \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "..\\tests\\test_compliance_officer.py::TestComplianceOfficerAgent::test_api_call_parameters \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m10 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "\n",
      "============================================================\n",
      "üìä INTEGRATION TEST RESULTS:\n",
      "   Foundation Components: ‚úÖ PASS\n",
      "   Risk Analyst Agent: ‚úÖ PASS\n",
      "   Compliance Officer Agent: ‚úÖ PASS\n",
      "   Overall Status: ‚úÖ ALL TESTS PASSED\n",
      "\n",
      "üéâ Your system is ready for production workflow testing!\n",
      "üìù Proceed to run the complete system demonstration.\n"
     ]
    }
   ],
   "source": [
    "# üß™ Workflow Integration Testing\n",
    "# Validate your complete system with integration tests\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add tests directory to Python path for importing test modules\n",
    "project_root = os.path.abspath('..')\n",
    "tests_path = os.path.join(project_root, 'tests')\n",
    "if tests_path not in sys.path:\n",
    "    sys.path.insert(0, tests_path)\n",
    "\n",
    "print(f\"üìÅ Added tests directory to Python path: {tests_path}\")\n",
    "\n",
    "def run_integration_tests():\n",
    "    \"\"\"\n",
    "    Run comprehensive integration tests to validate the complete workflow\n",
    "    \n",
    "    Tests include:\n",
    "    1. Foundation components integration\n",
    "    2. Agent communication and data flow\n",
    "    3. End-to-end workflow execution\n",
    "    4. Error handling and edge cases\n",
    "    5. Output validation and compliance\n",
    "    \"\"\"\n",
    "    print(\"üß™ Comprehensive Integration Testing\")\n",
    "    print(\"üìã TODO: Uncomment and run after implementing complete workflow\")\n",
    "    \n",
    "    # Uncomment when your complete system is ready:\n",
    "    try:\n",
    "        # Import all test modules\n",
    "        from test_foundation import TestCustomerData, TestAccountData, TestTransactionData, TestCaseData\n",
    "        from test_risk_analyst import TestRiskAnalystAgent\n",
    "        from test_compliance_officer import TestComplianceOfficerAgent\n",
    "        import pytest\n",
    "        \n",
    "        pytest_flags = [\n",
    "            \"-v\", \n",
    "            \"--tb=short\",\n",
    "            \"-p\", \"no:cacheprovider\",\n",
    "            \"-W\", \"ignore::pytest.PytestAssertRewriteWarning\"\n",
    "        ]\n",
    "\n",
    "        print(\"üîç Running Foundation Component Tests...\")\n",
    "        foundation_result = pytest.main([\n",
    "            f\"{tests_path}/test_foundation.py\", \n",
    "            \"-v\", \n",
    "            \"--tb=short\"\n",
    "        ] + pytest_flags)\n",
    "        \n",
    "        print(\"üîç Running Risk Analyst Agent Tests...\")\n",
    "        risk_result = pytest.main([\n",
    "            f\"{tests_path}/test_risk_analyst.py\", \n",
    "            \"-v\", \n",
    "            \"--tb=short\"\n",
    "        ] + pytest_flags)\n",
    "        \n",
    "        print(\"üìù Running Compliance Officer Agent Tests...\")\n",
    "        compliance_result = pytest.main([\n",
    "            f\"{tests_path}/test_compliance_officer.py\", \n",
    "            \"-v\", \n",
    "            \"--tb=short\"\n",
    "        ] + pytest_flags)\n",
    "        \n",
    "        # Calculate overall test results\n",
    "        all_passed = foundation_result == 0 and risk_result == 0 and compliance_result == 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä INTEGRATION TEST RESULTS:\")\n",
    "        print(f\"   Foundation Components: {'‚úÖ PASS' if foundation_result == 0 else '‚ùå FAIL'}\")\n",
    "        print(f\"   Risk Analyst Agent: {'‚úÖ PASS' if risk_result == 0 else '‚ùå FAIL'}\")\n",
    "        print(f\"   Compliance Officer Agent: {'‚úÖ PASS' if compliance_result == 0 else '‚ùå FAIL'}\")\n",
    "        print(f\"   Overall Status: {'‚úÖ ALL TESTS PASSED' if all_passed else '‚ùå SOME TESTS FAILED'}\")\n",
    "        \n",
    "        if all_passed:\n",
    "            print(\"\\nüéâ Your system is ready for production workflow testing!\")\n",
    "            print(\"üìù Proceed to run the complete system demonstration.\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è Fix failing tests before running the complete workflow.\")\n",
    "            print(\"üìù Return to previous notebooks to fix component issues.\")\n",
    "        \n",
    "        return all_passed\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Import Error: {e}\")\n",
    "        print(\"üí° Make sure all components are implemented:\")\n",
    "        print(\"   ‚Ä¢ foundation_sar.py\")\n",
    "        print(\"   ‚Ä¢ risk_analyst_agent.py\") \n",
    "        print(\"   ‚Ä¢ compliance_officer_agent.py\")\n",
    "        return False\n",
    "\n",
    "def validate_workflow_components():\n",
    "    \"\"\"Validate that all required components are available for integration\"\"\"\n",
    "    print(\"üîç Validating Workflow Components\")\n",
    "    \n",
    "    components_status = {\n",
    "        'foundation_sar': False,\n",
    "        'risk_analyst_agent': False,\n",
    "        'compliance_officer_agent': False,\n",
    "        'test_modules': False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check foundation components\n",
    "        from foundation_sar import CustomerData, CaseData, ExplainabilityLogger, DataLoader\n",
    "        components_status['foundation_sar'] = True\n",
    "        print(\"‚úÖ Foundation components available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå Foundation components not available\")\n",
    "    \n",
    "    try:\n",
    "        # Check risk analyst agent\n",
    "        from risk_analyst_agent import RiskAnalystAgent\n",
    "        components_status['risk_analyst_agent'] = True\n",
    "        print(\"‚úÖ Risk Analyst Agent available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå Risk Analyst Agent not available\")\n",
    "    \n",
    "    try:\n",
    "        # Check compliance officer agent\n",
    "        from compliance_officer_agent import ComplianceOfficerAgent\n",
    "        components_status['compliance_officer_agent'] = True\n",
    "        print(\"‚úÖ Compliance Officer Agent available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå Compliance Officer Agent not available\")\n",
    "    \n",
    "    try:\n",
    "        # Check test modules\n",
    "        from test_foundation import TestCustomerData\n",
    "        from test_risk_analyst import TestRiskAnalystAgent  \n",
    "        from test_compliance_officer import TestComplianceOfficerAgent\n",
    "        components_status['test_modules'] = True\n",
    "        print(\"‚úÖ Test modules available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå Test modules not available\")\n",
    "    \n",
    "    all_ready = all(components_status.values())\n",
    "    \n",
    "    print(f\"\\nüìä Component Status: {'‚úÖ ALL READY' if all_ready else '‚ö†Ô∏è INCOMPLETE'}\")\n",
    "    if not all_ready:\n",
    "        print(\"üí° Complete missing components before running integration tests\")\n",
    "    \n",
    "    return all_ready\n",
    "\n",
    "# Run component validation\n",
    "components_ready = validate_workflow_components()\n",
    "\n",
    "# Run integration tests if components are ready\n",
    "if components_ready:\n",
    "    print(\"\\nüöÄ All components ready - you can run integration tests!\")\n",
    "    run_integration_tests()\n",
    "else:\n",
    "    print(\"\\nüìã Complete component implementation first, then run integration tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e71047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã TODO: Run end-to-end test after implementing complete workflow\n",
      "üéØ End-to-End Workflow Testing\n",
      "üìã TODO: Implement after completing all workflow components\n",
      "üöÄ Starting end-to-end workflow test...\n",
      "üìä Loading test data...\n",
      "üìä Loading Financial Data...\n",
      "üìà Loaded: 150 customers, 178 accounts, 4268 transactions\n",
      "üîç Testing customer screening...\n",
      "üîç Customer Risk Screening...\n",
      "üìä Selected 2 high-risk customers for detailed AI analysis.\n",
      "‚úÖ Selected 2 customers for testing\n",
      "ü§ñ Testing automated workflow...\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "‚úÖ Successfully processed: Jacqueline Rodriguez\n",
      "üîç DEBUG: Starting narrative generation...\n",
      "‚úÖ Successfully processed: Michael Stanley\n",
      "\n",
      "üìä END-TO-END TEST RESULTS:\n",
      "   Cases Processed: 2\n",
      "   SARs Generated: 2\n",
      "   Errors: 0\n",
      "\n",
      "üéâ END-TO-END TEST PASSED!\n",
      "‚úÖ Your complete workflow is ready for production use!\n"
     ]
    }
   ],
   "source": [
    "# üéØ End-to-End Workflow Testing\n",
    "# Test the complete workflow with known test scenarios\n",
    "\n",
    "def test_complete_workflow():\n",
    "    \"\"\"\n",
    "    Test the complete SAR processing workflow end-to-end\n",
    "    \n",
    "    This test should:\n",
    "    1. Load test data (can use a subset of actual data)\n",
    "    2. Run customer screening\n",
    "    3. Execute two-stage AI analysis\n",
    "    4. Simulate human decisions (automated for testing)\n",
    "    5. Generate SAR documents\n",
    "    6. Validate all outputs\n",
    "    7. Check audit trail completeness\n",
    "    \"\"\"\n",
    "    print(\"üéØ End-to-End Workflow Testing\")\n",
    "    print(\"üìã TODO: Implement after completing all workflow components\")\n",
    "    \n",
    "    # Example end-to-end test structure (uncomment when ready):\n",
    "    try:\n",
    "        print(\"üöÄ Starting end-to-end workflow test...\")\n",
    "        \n",
    "        # Test data preparation\n",
    "        print(\"üìä Loading test data...\")\n",
    "        customers_data, accounts_data, transactions_data = load_and_preprocess_data()\n",
    "        \n",
    "        if not customers_data:\n",
    "            print(\"‚ö†Ô∏è No test data available - implement data loading first\")\n",
    "            return False\n",
    "        \n",
    "        # Test customer screening\n",
    "        print(\"üîç Testing customer screening...\")\n",
    "        selected_customers = screen_high_risk_customers(\n",
    "            customers_data, accounts_data, transactions_data, top_n=2\n",
    "        )\n",
    "        \n",
    "        if not selected_customers:\n",
    "            print(\"‚ö†Ô∏è No customers selected - check screening criteria\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"‚úÖ Selected {len(selected_customers)} customers for testing\")\n",
    "        \n",
    "        # Test workflow with automated decisions (for testing)\n",
    "        print(\"ü§ñ Testing automated workflow...\")\n",
    "        test_results = {\n",
    "            'cases_processed': 0,\n",
    "            'sars_generated': 0,\n",
    "            'errors': []\n",
    "        }\n",
    "        \n",
    "        for customer_data in selected_customers:\n",
    "            try:\n",
    "                # Create case\n",
    "                loader = DataLoader(explainability_logger)\n",
    "                case_data = loader.create_case_from_data(\n",
    "                    customer_data['customer'],\n",
    "                    customer_data['accounts'],\n",
    "                    customer_data['transactions']\n",
    "                )\n",
    "                \n",
    "                # Test Risk Analyst\n",
    "                risk_analysis = risk_agent.analyze_case(case_data)\n",
    "                assert hasattr(risk_analysis, 'classification'), \"Risk analysis missing classification\"\n",
    "                assert hasattr(risk_analysis, 'confidence_score'), \"Risk analysis missing confidence\"\n",
    "                \n",
    "                # Test Compliance Officer (simulate approval)\n",
    "                compliance_review = compliance_agent.generate_compliance_narrative(case_data, risk_analysis)\n",
    "                assert hasattr(compliance_review, 'narrative'), \"Compliance review missing narrative\"\n",
    "                \n",
    "                # Test SAR generation\n",
    "                sar_document = create_sar_document(case_data, risk_analysis, compliance_review)\n",
    "                assert sar_document, \"SAR document generation failed\"\n",
    "                \n",
    "                test_results['cases_processed'] += 1\n",
    "                test_results['sars_generated'] += 1\n",
    "                \n",
    "                print(f\"‚úÖ Successfully processed: {customer_data['customer']['name']}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                test_results['errors'].append(f\"Error processing {customer_data['customer']['name']}: {e}\")\n",
    "                print(f\"‚ùå Error processing: {customer_data['customer']['name']}: {e}\")\n",
    "        \n",
    "        # Test results summary\n",
    "        print(\"\\nüìä END-TO-END TEST RESULTS:\")\n",
    "        print(f\"   Cases Processed: {test_results['cases_processed']}\")\n",
    "        print(f\"   SARs Generated: {test_results['sars_generated']}\")\n",
    "        print(f\"   Errors: {len(test_results['errors'])}\")\n",
    "        \n",
    "        if test_results['errors']:\n",
    "            print(\"‚ùå Test Errors:\")\n",
    "            for error in test_results['errors']:\n",
    "                print(f\"     ‚Ä¢ {error}\")\n",
    "        \n",
    "        success = len(test_results['errors']) == 0 and test_results['cases_processed'] > 0\n",
    "        \n",
    "        if success:\n",
    "            print(\"\\nüéâ END-TO-END TEST PASSED!\")\n",
    "            print(\"‚úÖ Your complete workflow is ready for production use!\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è END-TO-END TEST HAD ISSUES\")\n",
    "            print(\"üìù Fix the errors above before deploying to production\")\n",
    "        \n",
    "        return success\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå End-to-end test failed: {e}\")\n",
    "        print(\"üí° Ensure all components are properly implemented\")\n",
    "        return False\n",
    "\n",
    "# Run end-to-end test\n",
    "print(\"üìã TODO: Run end-to-end test after implementing complete workflow\")\n",
    "test_success = test_complete_workflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
